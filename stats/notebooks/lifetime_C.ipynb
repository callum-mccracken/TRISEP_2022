{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36edb513-4f9e-40e9-8c9c-fab782d43475",
   "metadata": {},
   "source": [
    "# 2.C: Include more complexity to the model\n",
    "\n",
    "Includes background process, time offset, and time resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5df84d4-d029-4d56-9f74-6e59f2b70657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules needed for this tutorial\n",
    "from trisep.LifetimeExperiment import LifetimeExperiment, SimulatedLifetimeExperiment\n",
    "from trisep.MarkovChain import MarkovChain\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background') # only include this if you use a dark background for Jupyter Lab\n",
    "\n",
    "from iminuit import Minuit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee452262-b4d6-4e6a-babf-0738faaf692e",
   "metadata": {},
   "source": [
    "## Compare data from the real experiment and from the simulation of a perfect setup\n",
    "\n",
    "Make a histogram of lifetimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624ab551-ba17-4915-b896-1d677efaca37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# real experiment\n",
    "\n",
    "lifetime_experiment = LifetimeExperiment()\n",
    "\n",
    "lifetime_experiment.set_counting_time(10)  # specified in seconds: You will have to wait that long to get the result!\n",
    "counting_time = lifetime_experiment.get_counting_time()  # read back the time to make sure it was set correctly\n",
    "\n",
    "lifetime_experiment.start()\n",
    "lab_times = lifetime_experiment.get_times()\n",
    "\n",
    "# simulation of perfect experiment\n",
    "\n",
    "sim_experiment = SimulatedLifetimeExperiment(isotope_lifetime=0.03)\n",
    "sim_experiment.set_counting_time(counting_time)\n",
    "\n",
    "sim_experiment.start()\n",
    "sim_times = sim_experiment.get_times()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9337e9f7-7d0e-447e-9e1b-e5c3e682b1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare histograms\n",
    "\n",
    "fig, axes = plt.subplots(1,2,figsize=(12, 6))\n",
    "\n",
    "for axis,times,title in zip(axes,[lab_times,sim_times],['real','perfect']):\n",
    "    axis.hist(times,bins=np.arange(-0.2,0.2,0.01))\n",
    "    axis.set_title(title)\n",
    "    axis.set_ylim(0.,15.*counting_time/10.)\n",
    "    axis.set_xlabel('lifetime (s)')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc5b0fd-4b24-4275-864b-0a0e50f63a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate likelihood of observing real data assuming perfect setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2548bb-ccc2-41c0-bcc0-8ece667a7535",
   "metadata": {},
   "source": [
    "## Additional complexity:\n",
    " - some of the times reported are due to a background process whose time distribution is uniform\n",
    " - the lifetime is measured by the difference in two clocks which may have a time offset\n",
    " - the device has finite time resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7bc38f-59fa-4fe2-91dc-f5d5f11fe777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare model to real data to model\n",
    "\n",
    "bin_width = 0.02\n",
    "\n",
    "plt.hist(lab_times,bins=np.arange(-0.2,0.2,bin_width))\n",
    "\n",
    "# ADD CODE to overlay the model pdf\n",
    "# USE the get_pdf(time) method of the sim_experiment object\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a5de25-7dc2-4f9f-957e-45905854ba94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now add the additional elements\n",
    "\n",
    "fig, axes = plt.subplots(1,3,figsize=(15, 4))\n",
    "\n",
    "for element,axis in enumerate(axes):\n",
    "    full_model = SimulatedLifetimeExperiment(isotope_lifetime=0.03)\n",
    "    \n",
    "    if element == 0:\n",
    "        full_model.set_background_fraction(0.2)\n",
    "        axis.set_title('background')\n",
    "    elif element == 1:\n",
    "        full_model.set_time_offset(-0.05)\n",
    "        axis.set_title('time offset')\n",
    "    elif element == 2:\n",
    "        full_model.set_time_resolution(0.01)\n",
    "        axis.set_title('time resolution')\n",
    "        \n",
    "# ADD CODE to overlay the model pdf\n",
    "# USE the get_pdf(time) method of the full_model object\n",
    "\n",
    "    axis.hist(lab_times,bins=np.arange(-0.2,0.2,bin_width))\n",
    "    axis.set_ylim(0.,40.*counting_time/10.)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bf5c99-73cc-4df3-97bf-7e01db06ca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This time we have no control experiments to give us more information about the additional parameters\n",
    "# The lifetime distribution will be used to estimate all of these\n",
    "\n",
    "# Find point estimnates and approximate intervals with minuit\n",
    "\n",
    "def get_full_neg_log_likelihood(tau,bf,t_off,t_sig):\n",
    "    full_model.set_isotope_lifetime(tau)\n",
    "    full_model.set_background_fraction(bf)\n",
    "    full_model.set_time_offset(t_off)\n",
    "    full_model.set_time_resolution(t_sig)\n",
    "    return -1.*full_model.get_log_likelihood(lab_times)\n",
    "\n",
    "get_full_neg_log_likelihood.errordef = Minuit.LIKELIHOOD\n",
    "\n",
    "m = Minuit(get_full_neg_log_likelihood, tau=0.03, bf=0.1, t_off=0., t_sig=0.01)\n",
    "m.limits['tau'] = (0., None)\n",
    "m.limits['bf'] = (0., 1.)\n",
    "m.limits['t_off'] = (-0.1,0.1)\n",
    "m.limits['t_sig'] = (0., 0.5)\n",
    "\n",
    "m.migrad()\n",
    "m.hesse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f51dc3-5724-4de1-b980-b1a003b06cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare distribution of lab_times with optimized full_model pdf\n",
    "\n",
    "bin_width = 0.02\n",
    "\n",
    "plt.hist(lab_times,bins=np.arange(-0.2,0.2,bin_width))\n",
    "\n",
    "# ADD CODE to overlay the model pdf\n",
    "# USE the get_pdf(time) method of the full_model object\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e05c50c-68cb-44e0-b762-010817a49ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minuit provides methods to show 2D contours of neg log likelihood around minimum (keeping other parameters fixed)\n",
    "# Even if priors are uniform, this is NOT equivalent to the marginalized posterior. Be careful in interpretting such contours.\n",
    "# Recommendation: Use the MCMC approach to show the marginalized posterior.\n",
    "\n",
    "m.draw_contour('t_off','t_sig');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de49661-262a-4924-8f98-ae444c824bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Often, an adhoc approach to reduce dimensionality of the likelihood function is to optimize over\n",
    "# the other variables. Frequentist intervals constructed in this way do not necessarily have good coverage.\n",
    "\n",
    "# Warning: this can take time to complete and may fail when sample size is small.\n",
    "# m.draw_mncontour('t_off','t_sig');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cda451-41f5-44ef-bd1c-53b42ae140b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the posterior using MCMC\n",
    "\n",
    "def logP(params):\n",
    "    tau = params['tau']\n",
    "    bf = params['bf']\n",
    "    t_off = params['t_off']\n",
    "    t_sig = params['t_sig']\n",
    "\n",
    "    neg_log_likelihood = get_full_neg_log_likelihood(tau,bf,t_off,t_sig)\n",
    "\n",
    "    # assuming uniform prior:\n",
    "    return -1.*neg_log_likelihood\n",
    "\n",
    "parameters = [\n",
    "    {'name':'tau','start':0.03,'step':0.001,'min':0.001,'max':1.},\n",
    "    {'name':'bf','start':0.06,'step':0.05,'min':0.0,'max':0.5},\n",
    "    {'name':'t_off','start':0.,'step':0.005,'min':-0.2,'max':0.2},\n",
    "    {'name':'t_sig','start':0.02,'step':0.005,'min':0.,'max':0.1}\n",
    "]\n",
    "mcmc = MarkovChain(parameters, logP)\n",
    "chain = mcmc.get_chain(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a56a9f-1dae-497c-bf55-edf0cfb5078e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(chain)\n",
    "pd.plotting.scatter_matrix(df,s=3,figsize=[10,10]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f15e8d-f162-4eec-83eb-866fb3cf9926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marginalize to 1D posterior distribution for lifetime and find 90% credible interval\n",
    "\n",
    "tau_list = [dict['tau'] for dict in chain]\n",
    "plt.hist(tau_list)\n",
    "plt.show()\n",
    "\n",
    "tau_low = ?\n",
    "tau_high = ?\n",
    "\n",
    "print('90% credible interval for lifetime: [',round(tau_low,3),',',round(tau_high,3),']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e900716-7fc1-40ec-abe3-b76d1bc96e31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('trisep')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "c58921df5c6489fa188207e277f3720ee4272b5f4b5ba9c77debc4d7527b0f01"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
